paste(mt[1, ], mt[2,], sep="_")
paste(mt[1, ], mt[3,], sep="_")
paste(unique(paste(mt[1, ], mt[3,], sep="_")), collapse=", ")
stds<- paste(unique(paste(mt[1, ], mt[3,], sep="_")), collapse=", ")
stdsa<-c()
for(i in 1:length(unm)){
stds<- tb[which(as.character(unm[i])==tb[,1]),2]
mt<- matrix(unlist(strsplit(as.character(stds), split="_")), nrow=3)
stds<- paste(unique(paste(mt[1, ], mt[3,], sep="_")), collapse=", ")
stdsa<- append(stdsa, stds)
}
data.frame(umn ,stdsa)
data.frame(umn,stdsa)
data.frame(unm,stdsa)
View(data.frame(unm,stdsa))
setwd("~/Documents/GitHub/Wheat-Selection-Decisons-2020")
library(asreml)
library(reshape)
dfall<- read.csv('predicted values table.csv', row.names=1)
tstprv<- c('07-19334','13-1960','15-2639','16-22039','16-23348','16-23941',
'16-23972','16-36206','16-36752','16-8048','16-8605',
'17-17739','17-23874','17-23904','17-25205','17-29544',
'17-8626','US16-IL-061-029','US16-IL-061-074','US16-IL-061-132',
'US16-IL-062-031','US16-IL-064-006','US16-IL-064-160')
tb<- unique(dfall[which(dfall$name %in% tstprv),c('name','studyName')])
tb<- tb[-grep("Adv|Pr",tb[,2]),]
unm<- unique(tb[,1])
stdsa<-c()
for(i in 1:length(unm)){
stds<- tb[which(as.character(unm[i])==tb[,1]),2]
mt<- matrix(unlist(strsplit(as.character(stds), split="_")), nrow=3)
stds<- paste(unique(paste(mt[1, ], mt[3,], sep="_")), collapse=", ")
stdsa<- append(stdsa, stds)
}
View(data.frame(unm,stdsa))
head(advlist)
gsub("-", ".", advlist[,1])
advlist[,1]
advlist
gsub("-", ".", advlist)
gsub("US", "", gsub("-", ".", advlist))
gsub("IL", "", gsub("US", "", gsub("-", ".", advlist)))
gsub("MFRS", "", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist))))
gsub("MSFRS", "", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist))))
order(gsub("MSFRS", "", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist)))))
advlist[order(gsub("MSFRS", "", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist))))),]
advlist[order(gsub("MSFRS", "", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist)))))]
advlist[-c(1:5)][order(gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))))]
advlist[-c(1:5)][order(-gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))))]
?order
advlist[-c(1:5)][order(gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), decreasing=T)]
advlist[-c(1:5)][order(as.numeric(gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), decreasing=T))]
advlist[-c(1:5)][order(as.numeric(gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), decreasing=T))]
[
advlist[-c(1:5)][order(as.numeric(gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), decreasing=T))]
advlist[-c(1:5)][order(as.numeric(gsub(gsub(".", "", "MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)]))))), decreasing=T))]
gsub(gsub(".", "", "MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)]))))
)
gsub(gsub(".", "", "MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))))
gsub(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))))
)
gsub(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)]))))))
gsub(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)]))))))gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)]))))
gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)]))))
gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))))
gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T)
order(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T))
ord<- order(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T))
advlist[-c(1:5)][ord]
ord<- order(as.numeric(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T)))
advlist[-c(1:5)][ord]
as.numeric(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T))
ord<- order(as.numeric(gsub(".", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", "0", advlist[-c(1:5)])))), fixed=T)))
advlist[-c(1:5)][ord]
ord<- order(as.numeric(gsub("..", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T)))
ord
advlist[-c(1:5)][ord]
as.numeric(gsub("..", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T))
gsub("..", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)]))))
)
gsub("..", "", gsub("MSFRS", "99999999", gsub("IL", "", gsub("US", "", gsub("-", ".", advlist[-c(1:5)])))), fixed=T)
install.packages(gtools)
install.packages('gtools')
mixedsort(advlist[-c(1:5)])
library(gtools)
mixedsort(advlist[-c(1:5)])
mixedorder(advlist[-c(1:5)])
mixedsort(advlist[-c(1:5)])
mixedsort(gsub("-", "", advlist[-c(1:5)]))
advlist[-c(1:5)][mixedorder(gsub("-", "", advlist[-c(1:5)]))]
advlist[-c(1:5)][mixedorder(gsub("-", "A", advlist[-c(1:5)]))]
c(advlist[c(1:5)], advlist[-c(1:5)][mixedorder(gsub("-", "A", advlist[-c(1:5)]))])
write.csv(advlist, file='advanced list 2020.csv')
getwd()
advlist<- c(advlist[c(1:5)], advlist[-c(1:5)][mixedorder(gsub("-", "A", advlist[-c(1:5)]))])
View(advlist)
write.csv(advlist, file='advanced list 2020.csv')
write.csv(advlist, file='advanced list 2020.csv')
advlist %in% selected1[,1]
which(advlist %in% selected1[,1])
source<- rep("Checks", 'Selected from Advanced 2019-2020')
length(advlist)
source<- rep("Checks",5), rep('Selected from Advanced 2019-2020', 170)
source<- c(rep("Checks",5), rep('Selected from Advanced 2019-2020', 170))
which(advlist %in% selected1[,1])
source[which(advlist %in% selected1[,1])]
source[which(advlist %in% selected1[,1])]<- "Selected from Prelim 2019-2020"
advlist<- data.frame(advlist, source)
advlist
write.csv(advlist, file='advanced list 2020.csv')
nonselected<- wide3[which(wide3$ranking>139),]
nonselected
setwd("~/Documents/GitHub/Wheat-Selection-Decisons-2020")
dfall<- read.csv('predicted values table.csv', row.names=1)
bluesYld<- dfall[which(dfall$studyName %in% c('Pr_Car_20','Pr_Neo_20','Pr_Stj_20','Pr_Urb_20', 'Pr_Scb_20','Pr_Sbmv_20')),]
##Functions to use later
#function to check model convergence and update until converged (tolerate a 1.5% change in components)
mkConv<- function(mod){
pctchg<- summary(mod)$varcomp[,c('%ch')]
while(any(pctchg >2, na.rm=TRUE)){
mod<-suppressWarnings(update(mod))
pctchg<- summary(mod)$varcomp[,c('%ch')]
}
return(mod)
}
#add rows for the missing values
a<- cast(bluesYld, name+studyName~trait, value='predicted.value')
b<- cast(bluesYld, name+studyName~trait, value='standard.error')
mta<- melt(a)
mtb<- melt(b)
#estimate weights based on the standard error
wt<- 1/(mtb$value^2)
#set missing weights to zero
wt[which(is.na(wt))]<- 0
#add weight to the dataset
df<- data.frame(mta, wt)
df<- droplevels.data.frame(df)
#fit model across locations
mod<- asreml(fixed=value~1+studyName+trait+studyName:trait, random=~us(trait):name,
data=df, weights=wt, family = asr_gaussian(dispersion = 1))
mod<- mkConv(mod)
#get the blups + means across locations for yield and test weight
p<- predict(mod, classify = 'name:trait', levels= list(trait=c('Grain.yield...bu.ac','Grain.test.weight...lbs.bu')),
pworkspace=64e6,
present=list(c("studyName"),prwts=c(.25,.25,0,0,.25,.25)))
blup<- p$pvals
#get the blups + means across locations for height
p<- predict(mod, classify = 'name:trait', pworkspace=64e6,
present=list(c("studyName"),
prwts=c(0,0.5,0,0,0, 0)))
blupht<- p$pvals
blupht<- blupht[which(blupht$trait=='Plant.height.inches'),]
#get the blups + means across locations for julain
p<- predict(mod, classify = 'name:trait', pworkspace=64e6,
present=list(c("studyName"),
prwts=c(0,0,0,0,0,1)))
blupjul<- p$pvals
blupjul<- blupjul[which(blupjul$trait=="Heading.time...Julian.date..JD.."),]
#get the blups + means across locations for scab
p<- predict(mod, classify = 'name:trait', pworkspace=64e6,
present=list(c("studyName"),
prwts=c(0,0,0,1,0,0)))
blupscb<- na.omit(p$pvals)
blupscb<- blupscb[-which(blupscb[,2]=='Heading.time...Julian.date..JD..'),]
#get the blups + means across locations for sbmv
p<- predict(mod, classify = 'name:trait', pworkspace=64e6,
present=list(c("studyName"),
prwts=c(0,0,1,0,0,0)))
blupsbmv<- na.omit(p$pvals)
#combine results
allblup<- rbind(blup, blupht, blupjul, blupscb, blupsbmv)
wide<- cast(allblup, name~trait, value='predicted.value')
for(i in 2:ncol(wide)){
wide[,i]<- scale(wide[, i], scale=FALSE)
if(NA %in% wide[,i]){
wide[which(is.na(wide[,i])),i]<- mean(wide[,i], na.rm=T)
}
}
##calculate indies
balancedIX<- wide$Grain.test.weight...lbs.bu * 0.5 +
wide$Grain.yield...bu.ac * 2.5 +
wide$Heading.time...Julian.date..JD.. * -3.7 +
wide$FHB.grain.incidence.....* -0.06  +
wide$FHB.incidence.....* -0.03  +
wide$FHB.severity.....* -0.02  +
wide$Plant.height.inches * -3.2+
wide$SBMV * .1
#add index to the table
wide2<- cbind(wide, balancedIX)
#check correlation matrix
as.matrix(cor(wide2[,-1])[,'balancedIX'])
#matrix
wide3<- data.frame(wide2, ranking=rank(-wide2$balancedIX))
rmv<- c('18-14132', '18-14647','18-15357','18-1050','18-1435','18-370','18-2872',
'18-16216','18-16368','18-4772','18-1108','18-4022','18-8149',
'18-3314','18-8907','18-10148','18-14308','18-12636','18-15271','18-26107','18-870',
'Pio25R74', 'Pio 25R74', '07-4415','02-18228')
wide3<- wide3[-which(wide3[,1] %in% rmv),]
selected<- wide3[which(wide3$ranking<=139),]
#select from the non-selected for the Nifa North
nonselected<- wide3[which(wide3$ranking>139),]
nonselected
order(nonselected$ranking)
nonselected[order(nonselected$ranking),]
nonselected[order(nonselected$ranking),][1:80,]
nonselected[order(nonselected$ranking),][1:80,1]
regionalAdvanced1list<- nonselected[order(nonselected$ranking),][1:80,1]
regionalAdvanced1list<- c(regionalAdvanced1list[mixedorder(gsub("-", "A",regionalAdvanced1list))])
regionalAdvanced1list
regionalAdvanced1list<- nonselected[order(nonselected$ranking),][1:80,1]
library(gtools)
regionalAdvanced1list<- regionalAdvanced1list[mixedorder(gsub("-", "A",regionalAdvanced1list))]
regionalAdvanced1list
write.csv(regionalAdvanced1list, file="selected from prelim 80 for NN trial.csv")
regionalAdvanced1list<- nonselected[order(nonselected$ranking),][1:60,1]
library(gtools)
regionalAdvanced1list<- regionalAdvanced1list[mixedorder(gsub("-", "A",regionalAdvanced1list))]
write.csv(regionalAdvanced1list, file="selected from prelim 60 for NN trial.csv")
regionalAdvanced1list
selected[-c(1:40),]
length(41:60)
length(41:70)
write.csv(selected, file="selected from advanced 30 for NN trial.csv")
selected<- wide3[which(wide3$ranking<=70),]
selected<- selected[41:70,]
write.csv(selected, file="selected from advanced 30 for NN trial.csv")
setwd("~/Documents/GitHub/Wheat-Selection-Decisons-2020")
library(asreml)
library(reshape)
dfall<- read.csv('predicted values table.csv', row.names=1)
bluesYld<- dfall[which(dfall$studyName %in% c('Adv_Car_20','Adv_Neo_20','Adv_StJ_20','Adv_Urb_20', 'Adv_Scb_20',"AdvHY_Urb_20",
'Adv_Car_19','Adv_Neo_19','Adv_Stj_19','Adv_Urb_19',"AdvHY_Urb_19",
'Pr[0-9]_Car_19','Pr[0-9]_Neo_19','Pr[0-9]_Stj_19','Pr[0-9]_Scb_19','Pr[0-9]_Urb_19',
'Adv_Scb_19', 'Adv_Scb_20', "Adv_Sbmv_20")),]
##Functions to use later
#function to check model convergence and update until converged (tolerate a 1.5% change in components)
mkConv<- function(mod){
pctchg<- summary(mod)$varcomp[,c('%ch')]
while(any(pctchg >2, na.rm=TRUE)){
mod<-suppressWarnings(update(mod))
pctchg<- summary(mod)$varcomp[,c('%ch')]
}
return(mod)
}
#add rows for the missing values
a<- cast(bluesYld, name+studyName~trait, value='predicted.value')
b<- cast(bluesYld, name+studyName~trait, value='standard.error')
mta<- melt(a)
mtb<- melt(b)
#estimate weights based on the standard error
wt<- 1/(mtb$value^2)
#set missing weights to zero
wt[which(is.na(wt))]<- 0
#add weight to the data-set
df<- data.frame(mta, wt)
df<- droplevels.data.frame(df)
####fit model across locations for agronomic traits
#subset the yield trials and agronomic traits
trts<- c('Grain.test.weight...lbs.bu', 'Grain.yield...bu.ac','Heading.time...Julian.date..JD..','Plant.height.inches',
'FHB.DON.content...ppm.','FHB.incidence.....','FHB.severity.....','FHB.grain.incidence.....', 'SBMV')
df<- df[which(df$trait %in% trts),]
#fit the model
mod<- asreml(fixed=value~1+trait, random=~studyName+studyName:trait+us(trait):name,
data=df, weights=wt, family = asr_gaussian(dispersion = 1),maxiter=500)
mod<- mkConv(mod)
p<- predict(mod, classify = 'name:trait')
allblup<- p$pvals
#summarize in wide format
wide<- cast(allblup, name~trait, value='predicted.value')
for(i in 2:ncol(wide)){
wide[,i]<- scale(wide[, i], scale=FALSE)
if(NA %in% wide[,i]){
wide[which(is.na(wide[,i])),i]<- mean(wide[,i], na.rm=T)
}
}
cr<- cor(wide[,-1])
colnames(cr)<- colnames(wide)[-1]
rownames(cr)<- colnames(wide)[-1]
##calculate indies
balancedIX<-wide$Grain.test.weight...lbs.bu * 0.5 +
wide$Grain.yield...bu.ac * 5 +
wide$Heading.time...Julian.date..JD.. * -6 +
wide$FHB.grain.incidence.....* -0.1  +
wide$FHB.incidence.....* -.5  +
wide$FHB.severity.....* -1.5  +
wide$FHB.DON.content...ppm. * -1
wide$Plant.height.inches * -12+
wide$SBMV * 2
#add index to the table
wide2<- cbind(wide, balancedIX)
#subset lines that have been in advanced for only one year
ixadv19<- which(wide$name %in% unique(df[which(df$studyName == 'Adv_Urb_19'),'name']))
ixadv20<- which(wide$name %in% unique(df[which(df$studyName == 'Adv_Urb_20'),'name']))
lines<- wide2[ixadv20[-which(ixadv20 %in% ixadv19)],1]
lines<- setdiff(lines, 'Pio25R74')
wide2<- wide2[match(lines, wide2[,1]),]
#matrix
wide3<- data.frame(wide2, ranking=rank(-wide2$balancedIX))
#estimate expected gain
expectedGain<- colMeans(wide3[which(wide3$ranking<=40),-1])- colMeans(wide3[which(wide3$ranking>40),-1])
as.matrix(round(expectedGain,2))
#get the selected
selected<- wide3[which(wide3$ranking<=40),]
selected<- selected[1:40,]
write.csv(selected, file="selected from advanced 40.csv")
#get the next best for the Nifa North (NN)
selected<- wide3[which(wide3$ranking<=70),]
selected<- selected[41:70,]
write.csv(selected, file="selected from advanced 30 for NN trial.csv")
setwd("~/Documents/GitHub/Wheat-Selection-Decisons-2020")
library(asreml)
library(reshape)
dfall<- read.csv('predicted values table.csv', row.names=1)
bluesYld<- dfall[which(dfall$studyName %in% c('Adv_Car_20','Adv_Neo_20','Adv_StJ_20','Adv_Urb_20', 'Adv_Scb_20',"AdvHY_Urb_20",
'Adv_Car_19','Adv_Neo_19','Adv_Stj_19','Adv_Urb_19',"AdvHY_Urb_19",
'Pr[0-9]_Car_19','Pr[0-9]_Neo_19','Pr[0-9]_Stj_19','Pr[0-9]_Scb_19','Pr[0-9]_Urb_19',
'Adv_Scb_19', 'Adv_Scb_20', "Adv_Sbmv_20")),]
##Functions to use later
#function to check model convergence and update until converged (tolerate a 1.5% change in components)
mkConv<- function(mod){
pctchg<- summary(mod)$varcomp[,c('%ch')]
while(any(pctchg >2, na.rm=TRUE)){
mod<-suppressWarnings(update(mod))
pctchg<- summary(mod)$varcomp[,c('%ch')]
}
return(mod)
}
#add rows for the missing values
a<- cast(bluesYld, name+studyName~trait, value='predicted.value')
b<- cast(bluesYld, name+studyName~trait, value='standard.error')
mta<- melt(a)
mtb<- melt(b)
#estimate weights based on the standard error
wt<- 1/(mtb$value^2)
#set missing weights to zero
wt[which(is.na(wt))]<- 0
#add weight to the data-set
df<- data.frame(mta, wt)
df<- droplevels.data.frame(df)
####fit model across locations for agronomic traits
#subset the yield trials and agronomic traits
trts<- c('Grain.test.weight...lbs.bu', 'Grain.yield...bu.ac','Heading.time...Julian.date..JD..','Plant.height.inches',
'FHB.DON.content...ppm.','FHB.incidence.....','FHB.severity.....','FHB.grain.incidence.....', 'SBMV')
df<- df[which(df$trait %in% trts),]
#fit the model
mod<- asreml(fixed=value~1+trait, random=~studyName+studyName:trait+us(trait):name,
data=df, weights=wt, family = asr_gaussian(dispersion = 1),maxiter=500)
mod<- mkConv(mod)
p<- predict(mod, classify = 'name:trait')
allblup<- p$pvals
#summarize in wide format
wide<- cast(allblup, name~trait, value='predicted.value')
for(i in 2:ncol(wide)){
wide[,i]<- scale(wide[, i], scale=FALSE)
if(NA %in% wide[,i]){
wide[which(is.na(wide[,i])),i]<- mean(wide[,i], na.rm=T)
}
}
cr<- cor(wide[,-1])
colnames(cr)<- colnames(wide)[-1]
rownames(cr)<- colnames(wide)[-1]
##calculate indies
balancedIX<-wide$Grain.test.weight...lbs.bu * 0.5 +
wide$Grain.yield...bu.ac * 5 +
wide$Heading.time...Julian.date..JD.. * -6 +
wide$FHB.grain.incidence.....* -0.1  +
wide$FHB.incidence.....* -.5  +
wide$FHB.severity.....* -1.5  +
wide$FHB.DON.content...ppm. * -1
wide$Plant.height.inches * -12+
wide$SBMV * 2
#add index to the table
wide2<- cbind(wide, balancedIX)
#subset lines that have been in advanced for only one year
ixadv19<- which(wide$name %in% unique(df[which(df$studyName == 'Adv_Urb_19'),'name']))
ixadv20<- which(wide$name %in% unique(df[which(df$studyName == 'Adv_Urb_20'),'name']))
lines<- wide2[ixadv20[-which(ixadv20 %in% ixadv19)],1]
lines<- setdiff(lines, 'Pio25R74')
wide2<- wide2[match(lines, wide2[,1]),]
#matrix
wide3<- data.frame(wide2, ranking=rank(-wide2$balancedIX))
#estimate expected gain
expectedGain<- colMeans(wide3[which(wide3$ranking<=40),-1])- colMeans(wide3[which(wide3$ranking>40),-1])
as.matrix(round(expectedGain,2))
#get the selected
selected<- wide3[which(wide3$ranking<=40),]
selected<- selected[1:40,]
write.csv(selected, file="selected from advanced 40.csv")
#get the next best for the Nifa North (NN)
nonselected<- wide3[which(wide3$ranking<=70),]
nonselected<- nonselected[41:70,]
library(gtools)
nonselected<- nonselected[mixedorder(gsub("-", "A",nonselected))]
write.csv(nonselected, file="selected from advanced 30 for NN trial.csv")
nonselected
#get the next best for the Nifa North (NN)
nonselected<- wide3[which(wide3$ranking<=70),]
nonselected<- nonselected[41:70,1]
library(gtools)
nonselected<- nonselected[mixedorder(gsub("-", "A",nonselected))]
write.csv(nonselected, file="selected from advanced 30 for NN trial.csv")
nonselected
nonselected
#get the next best for the Nifa North (NN)
nonselected<- wide3[which(wide3$ranking<=70),]
nonselected
nonselected[41:70,]
order(nonselected$ranking)
nonselected[order(nonselected$ranking),]
#get the next best for the Nifa North (NN)
nonselected<- wide3[which(wide3$ranking<=70),]
nonselected<- nonselected[order(nonselected$ranking),]
nonselected<- nonselected[order(nonselected$ranking),]
nonselected<- nonselected[41:70,1]
#get the next best for the Nifa North (NN)
nonselected<- wide3[which(wide3$ranking<=70),]
nonselected<- nonselected[order(nonselected$ranking),]
nonselected
nonselected[41:70,]
#get the next best for the Nifa North (NN)
nonselected<- wide3[which(wide3$ranking<=70),]
nonselected<- nonselected[order(nonselected$ranking),]
nonselected<- nonselected[41:70,1]
library(gtools)
nonselected<- nonselected[mixedorder(gsub("-", "A",nonselected))]
write.csv(nonselected, file="selected from advanced 30 for NN trial.csv")
setwd("~/Documents/GitHub/Wheat-Selection-Decisons-2020")
library(asreml)
library(reshape)
dfall<- read.csv('predicted values table.csv', row.names=1)
bluesYld<- dfall[which(dfall$studyName %in% c('Adv_Car_20','Adv_Neo_20','Adv_StJ_20','Adv_Urb_20', 'Adv_Scb_20',"AdvHY_Urb_20",
'Adv_Car_19','Adv_Neo_19','Adv_Stj_19','Adv_Urb_19',"AdvHY_Urb_19",
'Pr[0-9]_Car_19','Pr[0-9]_Neo_19','Pr[0-9]_Stj_19','Pr[0-9]_Scb_19','Pr[0-9]_Urb_19',
'Adv_Scb_19', 'Adv_Scb_20', "Adv_Sbmv_20")),]
##Functions to use later
#function to check model convergence and update until converged (tolerate a 1.5% change in components)
mkConv<- function(mod){
pctchg<- summary(mod)$varcomp[,c('%ch')]
while(any(pctchg >2, na.rm=TRUE)){
mod<-suppressWarnings(update(mod))
pctchg<- summary(mod)$varcomp[,c('%ch')]
}
return(mod)
}
#add rows for the missing values
a<- cast(bluesYld, name+studyName~trait, value='predicted.value')
b<- cast(bluesYld, name+studyName~trait, value='standard.error')
mta<- melt(a)
mtb<- melt(b)
#estimate weights based on the standard error
wt<- 1/(mtb$value^2)
#set missing weights to zero
wt[which(is.na(wt))]<- 0
#add weight to the data-set
df<- data.frame(mta, wt)
df<- droplevels.data.frame(df)
####fit model across locations for agronomic traits
#subset the yield trials and agronomic traits
trts<- c('Grain.test.weight...lbs.bu', 'Grain.yield...bu.ac','Heading.time...Julian.date..JD..','Plant.height.inches',
'FHB.DON.content...ppm.','FHB.incidence.....','FHB.severity.....','FHB.grain.incidence.....', 'SBMV')
df<- df[which(df$trait %in% trts),]
#fit the model
mod<- asreml(fixed=value~1+trait, random=~studyName+studyName:trait+us(trait):name,
data=df, weights=wt, family = asr_gaussian(dispersion = 1),maxiter=500)
mod<- mkConv(mod)
p<- predict(mod, classify = 'name:trait')
allblup<- p$pvals
#summarize in wide format
wide<- cast(allblup, name~trait, value='predicted.value')
for(i in 2:ncol(wide)){
wide[,i]<- scale(wide[, i], scale=FALSE)
if(NA %in% wide[,i]){
wide[which(is.na(wide[,i])),i]<- mean(wide[,i], na.rm=T)
}
}
cr<- cor(wide[,-1])
colnames(cr)<- colnames(wide)[-1]
rownames(cr)<- colnames(wide)[-1]
##calculate indies
balancedIX<-wide$Grain.test.weight...lbs.bu * 0.5 +
wide$Grain.yield...bu.ac * 5 +
wide$Heading.time...Julian.date..JD.. * -6 +
wide$FHB.grain.incidence.....* -0.1  +
wide$FHB.incidence.....* -.5  +
wide$FHB.severity.....* -1.5  +
wide$FHB.DON.content...ppm. * -1
wide$Plant.height.inches * -12+
wide$SBMV * 2
#add index to the table
wide2<- cbind(wide, balancedIX)
#subset lines that have been in advanced for only one year
ixadv19<- which(wide$name %in% unique(df[which(df$studyName == 'Adv_Urb_19'),'name']))
ixadv20<- which(wide$name %in% unique(df[which(df$studyName == 'Adv_Urb_20'),'name']))
lines<- wide2[ixadv20[-which(ixadv20 %in% ixadv19)],1]
lines<- setdiff(lines, 'Pio25R74')
wide2<- wide2[match(lines, wide2[,1]),]
#matrix
wide3<- data.frame(wide2, ranking=rank(-wide2$balancedIX))
#estimate expected gain
expectedGain<- colMeans(wide3[which(wide3$ranking<=40),-1])- colMeans(wide3[which(wide3$ranking>40),-1])
as.matrix(round(expectedGain,2))
#get the selected
selected<- wide3[which(wide3$ranking<=40),]
selected<- selected[1:40,]
write.csv(selected, file="selected from advanced 40.csv")
#get the next best for the Nifa North (NN)
nonselected<- wide3[which(wide3$ranking<=70),]
nonselected<- nonselected[order(nonselected$ranking),]
nonselected<- nonselected[41:70,1]
library(gtools)
nonselected<- nonselected[mixedorder(gsub("-", "A",nonselected))]
write.csv(nonselected, file="selected from advanced 30 for NN trial.csv")
